{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if gpu exists, need it to optimize run time\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "#### The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "#### The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training sample is 50000, each sample is a 32 by 32 image, 3RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]#y_train is a 2D array, for our classification having 1D array is good enough. so we will convert this to now 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 4 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 4 1]\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot some images to see what they are\n",
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. \n",
    "#### Hence to normalize in 0-->1 range, we need to divide it by 255\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build ANN model for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.8115 - accuracy: 0.3562\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 79s 50ms/step - loss: 1.6234 - accuracy: 0.4267\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 1.5411 - accuracy: 0.4561\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.4828 - accuracy: 0.4779\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.4310 - accuracy: 0.4944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1730fff6f40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'), # 3000 neurons\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    #10 for ten categories, softmax normalizes probability\n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',#when y is one-hot-encoded vector the use 'categorical_crossentroy' otherwise, 'sparse_categorical_crossentropy'\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN performs poorly, Accuracy is at 0.4944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.51      0.54      1000\n",
      "           1       0.44      0.78      0.57      1000\n",
      "           2       0.27      0.62      0.37      1000\n",
      "           3       0.45      0.17      0.25      1000\n",
      "           4       0.51      0.22      0.31      1000\n",
      "           5       0.52      0.24      0.33      1000\n",
      "           6       0.52      0.52      0.52      1000\n",
      "           7       0.64      0.48      0.55      1000\n",
      "           8       0.54      0.68      0.60      1000\n",
      "           9       0.58      0.43      0.49      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.50      0.47      0.45     10000\n",
      "weighted avg       0.50      0.47      0.45     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### metrics for each class\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
